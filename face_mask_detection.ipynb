{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fECGZ8nBCSBR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
        "print(\"Dataset downloaded to:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QOV-NUJ4BRj",
        "outputId": "f6ec2b9d-4cd8-4873-c0a7-84f48ed34b44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n",
            "Using Colab cache for faster access to the 'face-mask-dataset' dataset.\n",
            "Dataset downloaded to: /kaggle/input/face-mask-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw311SHo6hIz",
        "outputId": "a6890410-a880-43f7-ada6-55c8527216c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "464CebeY4q9L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to transform images to 128, 128\n",
        "transform=transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                         std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "# load dataset\n",
        "dataset=datasets.ImageFolder(root=f\"{path}/data\",transform=transform)"
      ],
      "metadata": {
        "id": "lX-SrG1N5-mc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.classes)  # e.g., ['with_mask', 'without_mask']\n",
        "print(dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i6G4aM89Rcz",
        "outputId": "9fdbff00-a2ba-4ea9-e52e-06a99816e1bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['with_mask', 'without_mask']\n",
            "{'with_mask': 0, 'without_mask': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create train validation set\n",
        "from torch.utils.data import random_split\n",
        "# 80% train 20% val\n",
        "train_size=int(0.8 * len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "puon8KiX9cL0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True,num_workers=2,pin_memory=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=32,shuffle=False,num_workers=2,pin_memory=True)"
      ],
      "metadata": {
        "id": "Q8muZ5YQ-wa4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCnn(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "      super().__init__()\n",
        "      self.features=nn.Sequential(\n",
        "          nn.Conv2d(in_channels,32,kernel_size=3,padding=\"same\"),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.MaxPool2d(2,2),\n",
        "          nn.Conv2d(32,64,kernel_size=3,padding=\"same\"),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.MaxPool2d(2,2)\n",
        "      )\n",
        "      self.classifier=nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(64*32*32,128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.3),\n",
        "          nn.Linear(128,64),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.3),\n",
        "          nn.Linear(64,2)\n",
        "      )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xE5eH91S_Vuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "epochs=90"
      ],
      "metadata": {
        "id": "EKi5Z2OkC81T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MyCnn(in_channels=3)\n",
        "model.to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=learning_rate,weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "onMlG9QkAfJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epoch_loss=0\n",
        "  for batch_features,batch_labels in train_loader:\n",
        "    batch_features,batch_labels=batch_features.to(device),batch_labels.to(device)\n",
        "    y_pred=model(batch_features)\n",
        "\n",
        "    loss=criterion(y_pred,batch_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oqN5hsiDO4_",
        "outputId": "d294b5d1-0211-4e9b-ae26-9ee9cabad3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Loss: 0.3075240361233237\n",
            "Epoch: 2 , Loss: 0.185983874633041\n",
            "Epoch: 3 , Loss: 0.12848221060263101\n",
            "Epoch: 4 , Loss: 0.08744775210063727\n",
            "Epoch: 5 , Loss: 0.05911637779088721\n",
            "Epoch: 6 , Loss: 0.042256372897003694\n",
            "Epoch: 7 , Loss: 0.04096471006050706\n",
            "Epoch: 8 , Loss: 0.02667923281080134\n",
            "Epoch: 9 , Loss: 0.015910620641618693\n",
            "Epoch: 10 , Loss: 0.015270047379465449\n",
            "Epoch: 11 , Loss: 0.009023009764965902\n",
            "Epoch: 12 , Loss: 0.006881304090259296\n",
            "Epoch: 13 , Loss: 0.00891729565958644\n",
            "Epoch: 14 , Loss: 0.005304221569223388\n",
            "Epoch: 15 , Loss: 0.010935157345494387\n",
            "Epoch: 16 , Loss: 0.008990909995518258\n",
            "Epoch: 17 , Loss: 0.005138792428143369\n",
            "Epoch: 18 , Loss: 0.005562798059794919\n",
            "Epoch: 19 , Loss: 0.004152923408404815\n",
            "Epoch: 20 , Loss: 0.011811861308237581\n",
            "Epoch: 21 , Loss: 0.009580370161640251\n",
            "Epoch: 22 , Loss: 0.005592835715216727\n",
            "Epoch: 23 , Loss: 0.008692803154257557\n",
            "Epoch: 24 , Loss: 0.002867512015688623\n",
            "Epoch: 25 , Loss: 0.006625828480874015\n",
            "Epoch: 26 , Loss: 0.0037645681625512436\n",
            "Epoch: 27 , Loss: 0.002901189211902492\n",
            "Epoch: 28 , Loss: 0.002357604874394277\n",
            "Epoch: 29 , Loss: 0.0015365902239979719\n",
            "Epoch: 30 , Loss: 0.0016309584231445722\n",
            "Epoch: 31 , Loss: 0.002404070707734838\n",
            "Epoch: 32 , Loss: 0.0008611321258010403\n",
            "Epoch: 33 , Loss: 0.0021517275733774917\n",
            "Epoch: 34 , Loss: 0.0024046002201566327\n",
            "Epoch: 35 , Loss: 0.001351371043014412\n",
            "Epoch: 36 , Loss: 0.0009072611739152043\n",
            "Epoch: 37 , Loss: 0.0019330030127599053\n",
            "Epoch: 38 , Loss: 0.0014649689236246742\n",
            "Epoch: 39 , Loss: 0.0027577788250156606\n",
            "Epoch: 40 , Loss: 0.001997947961341057\n",
            "Epoch: 41 , Loss: 0.0020545358131440726\n",
            "Epoch: 42 , Loss: 0.002606183081600951\n",
            "Epoch: 43 , Loss: 0.0016475413632532662\n",
            "Epoch: 44 , Loss: 0.0016259487391992735\n",
            "Epoch: 45 , Loss: 0.0020890134599109347\n",
            "Epoch: 46 , Loss: 0.001781826581409537\n",
            "Epoch: 47 , Loss: 0.0020128236921914443\n",
            "Epoch: 48 , Loss: 0.0007993669511285237\n",
            "Epoch: 49 , Loss: 0.0023335336724978825\n",
            "Epoch: 50 , Loss: 0.0015180732620490198\n",
            "Epoch: 51 , Loss: 0.0009171410750700753\n",
            "Epoch: 52 , Loss: 0.004524228312176746\n",
            "Epoch: 53 , Loss: 0.001465566204989387\n",
            "Epoch: 54 , Loss: 0.0008813492544836735\n",
            "Epoch: 55 , Loss: 0.0005118938129605397\n",
            "Epoch: 56 , Loss: 0.0008993460481662392\n",
            "Epoch: 57 , Loss: 0.0005242158393312164\n",
            "Epoch: 58 , Loss: 0.0012546694587689475\n",
            "Epoch: 59 , Loss: 0.00037072781149482154\n",
            "Epoch: 60 , Loss: 0.00048195054419315054\n",
            "Epoch: 61 , Loss: 0.0004119097321331423\n",
            "Epoch: 62 , Loss: 0.0004039234902761648\n",
            "Epoch: 63 , Loss: 0.0008567574680062344\n",
            "Epoch: 64 , Loss: 0.00034003873738355355\n",
            "Epoch: 65 , Loss: 0.00029896204552501545\n",
            "Epoch: 66 , Loss: 0.0003553273103500457\n",
            "Epoch: 67 , Loss: 0.0016726835139285\n",
            "Epoch: 68 , Loss: 0.0034912438638593332\n",
            "Epoch: 69 , Loss: 0.002363202765150524\n",
            "Epoch: 70 , Loss: 0.0005724433993560962\n",
            "Epoch: 71 , Loss: 0.0011715492098146954\n",
            "Epoch: 72 , Loss: 0.0007725174278054929\n",
            "Epoch: 73 , Loss: 0.0005823011908346199\n",
            "Epoch: 74 , Loss: 0.0011984552282423724\n",
            "Epoch: 75 , Loss: 0.001954199995454459\n",
            "Epoch: 76 , Loss: 0.0012950491636567157\n",
            "Epoch: 77 , Loss: 0.0013081063003853983\n",
            "Epoch: 78 , Loss: 0.0006005896524453255\n",
            "Epoch: 79 , Loss: 0.0005603196517958764\n",
            "Epoch: 80 , Loss: 0.0006069818267415259\n",
            "Epoch: 81 , Loss: 0.0003505847385975324\n",
            "Epoch: 82 , Loss: 0.0003513564502566229\n",
            "Epoch: 83 , Loss: 0.000344080705568563\n",
            "Epoch: 84 , Loss: 0.00037979467669947134\n",
            "Epoch: 85 , Loss: 0.0002959923296407727\n",
            "Epoch: 86 , Loss: 0.0002620304969374572\n",
            "Epoch: 87 , Loss: 0.0013511807453140301\n",
            "Epoch: 88 , Loss: 0.003356766517963698\n",
            "Epoch: 89 , Loss: 0.002621920734519617\n",
            "Epoch: 90 , Loss: 0.0008387374921637404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsRHuxQqEZnU",
        "outputId": "04975fd1-5f4b-4e91-f846-02d3e3d5f115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCnn(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=65536, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.3, inplace=False)\n",
              "    (7): Linear(in_features=64, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in val_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjU-bUJ6LBvy",
        "outputId": "6a91fa5d-29b8-49e5-e892-abcd209a9e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9424222369291859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on train data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWkZKR1eLeBg",
        "outputId": "b4d9edf3-ef9b-4c98-9461-9c67ad9d76df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in val_loader:\n",
        "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "        outputs = model(batch_features)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Accuracy counts\n",
        "        total += batch_labels.size(0)\n",
        "        correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "        # Store for confusion matrix\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "# Accuracy\n",
        "accuracy = correct / total\n",
        "print(f\"Val Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Val Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "7irGExplowWh",
        "outputId": "5e27f7dc-bb3a-4a38-f214-0c4b61fd3563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Accuracy: 0.9424\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save entire model\n",
        "torch.save(model.state_dict(), \"mycnn.pth\")\n"
      ],
      "metadata": {
        "id": "fjPs3fxHpb_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download to your local machine\n",
        "from google.colab import files\n",
        "files.download(\"mycnn.pth\")\n"
      ],
      "metadata": {
        "id": "DG_B3QdkpwDY",
        "outputId": "861e322c-bac6-4732-8e6e-4b78a9c3bb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97dbfe6b-df9c-4740-9a64-6466447f23c2\", \"mycnn.pth\", 33673450)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCnn_1(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "      super().__init__()\n",
        "      self.features=nn.Sequential(\n",
        "          nn.Conv2d(in_channels,32,kernel_size=3,padding=\"same\"),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.MaxPool2d(2,2),\n",
        "          nn.Conv2d(32,64,kernel_size=3,padding=\"same\"),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.MaxPool2d(2,2),\n",
        "          nn.AdaptiveAvgPool2d((4,4))\n",
        "      )\n",
        "      self.classifier=nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(64*4*4,128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.3),\n",
        "          nn.Linear(128,64),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(p=0.3),\n",
        "          nn.Linear(64,2)\n",
        "      )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yjl5JT_lT434"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "epochs=100"
      ],
      "metadata": {
        "id": "Sih6fpeCjXz1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1=MyCnn_1(in_channels=3)\n",
        "model_1.to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model_1.parameters(),lr=learning_rate,weight_decay=1e-4,momentum=0.9)"
      ],
      "metadata": {
        "id": "Pxx9IqNdjcol"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epoch_loss=0\n",
        "  for batch_features,batch_labels in train_loader:\n",
        "    batch_features,batch_labels=batch_features.to(device),batch_labels.to(device)\n",
        "    y_pred=model_1(batch_features)\n",
        "\n",
        "    loss=criterion(y_pred,batch_labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlFNkamRjnYo",
        "outputId": "8a98363c-6823-4b47-8d88-8397b1a3c460"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Loss: 0.3673731785602671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 , Loss: 0.2640629025599944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 , Loss: 0.2345628199123201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 , Loss: 0.20551500197440858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 , Loss: 0.19067658509605775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 , Loss: 0.18444044288819428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 , Loss: 0.1640397393041187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 , Loss: 0.14999145881405898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 , Loss: 0.13920690474056063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 , Loss: 0.11637620997452547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 , Loss: 0.10778880912179827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 , Loss: 0.09647099306639383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 , Loss: 0.0835818457632774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 , Loss: 0.07512956373787746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 , Loss: 0.06796057587095275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 , Loss: 0.0716166305257175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 , Loss: 0.06113101131031438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 , Loss: 0.05630562429207934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 , Loss: 0.05464843790744131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 , Loss: 0.04575202611481978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 , Loss: 0.04517729226351967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 , Loss: 0.03779987530307302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 , Loss: 0.024197558113084317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 , Loss: 0.02284642302313519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 , Loss: 0.027434690523444227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 , Loss: 0.028139372551801402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 , Loss: 0.02414042659455888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 , Loss: 0.020233141211854423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 , Loss: 0.029478312941916687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 , Loss: 0.025990419831556866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 , Loss: 0.01644720028595883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32 , Loss: 0.027753843577802254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33 , Loss: 0.015445765309441075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34 , Loss: 0.01743638188947453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35 , Loss: 0.016479590081679235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36 , Loss: 0.019591742786042955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37 , Loss: 0.011562405624543932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38 , Loss: 0.0067659160862382686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39 , Loss: 0.00863593888880493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40 , Loss: 0.013959704873447889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41 , Loss: 0.01574249589261685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42 , Loss: 0.009183344001170043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43 , Loss: 0.013576736533766037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44 , Loss: 0.008100414116737228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45 , Loss: 0.004600180613107551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46 , Loss: 0.005956022250348055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47 , Loss: 0.008064879209000321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48 , Loss: 0.010644907661867726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49 , Loss: 0.012870538956959204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50 , Loss: 0.009718691196486896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51 , Loss: 0.0041314377638473785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52 , Loss: 0.006090303110973552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53 , Loss: 0.006521425024241354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54 , Loss: 0.007541150759210261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55 , Loss: 0.005119569618251435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56 , Loss: 0.003595576264203936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57 , Loss: 0.0045530349435615805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58 , Loss: 0.003461334480983135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59 , Loss: 0.00665222817168455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60 , Loss: 0.005207892052866887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61 , Loss: 0.0026773629333619615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62 , Loss: 0.0077721558483933835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63 , Loss: 0.01008526491512471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64 , Loss: 0.004362683900542159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65 , Loss: 0.0019396637776408748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66 , Loss: 0.008443413582301613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67 , Loss: 0.011530247259896795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68 , Loss: 0.008378655030774387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69 , Loss: 0.005853664633310406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70 , Loss: 0.003091350622592246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71 , Loss: 0.002184353947650716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72 , Loss: 0.005560496439133559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73 , Loss: 0.0018685173029759892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74 , Loss: 0.003115057702342994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75 , Loss: 0.006080991171871266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76 , Loss: 0.006415901756050305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77 , Loss: 0.004891967668673455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78 , Loss: 0.006200639389586315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79 , Loss: 0.0035381034517163313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80 , Loss: 0.00314877774027712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81 , Loss: 0.003656122220717414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82 , Loss: 0.0016340611349180887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83 , Loss: 0.002796762887548446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84 , Loss: 0.0031658547509979054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85 , Loss: 0.006180477733658085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86 , Loss: 0.006508543948719249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87 , Loss: 0.0026209042197762908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88 , Loss: 0.006344186579590927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89 , Loss: 0.0010363864418671991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90 , Loss: 0.0022267728640885994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91 , Loss: 0.0009893852204280096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92 , Loss: 0.005604420359313062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93 , Loss: 0.0022297674435136556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94 , Loss: 0.0011227831462334776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95 , Loss: 0.0003818845663313104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96 , Loss: 0.000766237059084743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97 , Loss: 0.0013504489397890874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98 , Loss: 0.002138319751723985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99 , Loss: 0.0012029091007503118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 , Loss: 0.00044489157586386207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on train data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model_1(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "id": "OR8JxjtWjwTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7315531-d63a-4624-b834-27ee6ce19ec5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9998344918901027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save entire model\n",
        "torch.save(model_1.state_dict(), \"mycnn1.pth\")"
      ],
      "metadata": {
        "id": "fCCyGhqdH7td"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download to your local machine\n",
        "from google.colab import files\n",
        "files.download(\"mycnn1.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wckeGebdH_sz",
        "outputId": "0790fc4a-9ad6-4538-d062-2d96ff4e4441"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3db2c173-9a22-400a-a7fd-6b47595b7907\", \"mycnn1.pth\", 643789)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in val_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model_1(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx2VJ4d-ICRf",
        "outputId": "de060abf-c626-40b3-d38f-95000c28fa6b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9622766379880874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pd9FaNbBINgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}